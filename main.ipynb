{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import torch\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeResolution = np.array([25, 16, 17, 15, 15, 17, 14])\n",
    "minTimeResolution = min(timeResolution)\n",
    "n_frames = np.array([14516, 4372, 4625, 4078, 3983, 4943, 4593])\n",
    "\n",
    "def downsampleTimeResolution(timeResolution,minTimeResolution,n_frames,flag):\n",
    "    indices = np.round(np.linspace(0,timeResolution-1,minTimeResolution)).astype(int)\n",
    "    downsample = np.zeros([timeResolution])\n",
    "    downsample[indices] = 1\n",
    "    if flag==1:\n",
    "        downsampleFrames = np.hstack([downsample]*int(np.floor(n_frames/timeResolution))) # returns boolean array\n",
    "        print(downsampleFrames.shape)\n",
    "        return downsampleFrames\n",
    "    \n",
    "    else:\n",
    "        downsampleFrames = np.hstack([downsample]*int(np.floor(n_frames/timeResolution)))\n",
    "        downsampleFramesIdx = np.where(downsampleFrames==1) # return indices of frames to sample in video\n",
    "        print(downsampleFramesIdx[0].shape)\n",
    "        return downsampleFramesIdx\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14500,)\n",
      "(14500,)\n",
      "volunteer01.mp4:\n",
      "\n",
      "number of frames: 14516\n",
      "frame size: 640 x 480 \n",
      "\n",
      "(4368,)\n",
      "(4368,)\n",
      "volunteer02.mp4:\n",
      "\n",
      "number of frames: 4372\n",
      "frame size: 712 x 480 \n",
      "\n",
      "(4624,)\n",
      "(4624,)\n",
      "volunteer03.mp4:\n",
      "\n",
      "number of frames: 4625\n",
      "frame size: 700 x 480 \n",
      "\n",
      "(4065,)\n",
      "(4065,)\n",
      "volunteer04.mp4:\n",
      "\n",
      "number of frames: 4078\n",
      "frame size: 720 x 540 \n",
      "\n",
      "(3975,)\n",
      "(3975,)\n",
      "volunteer05.mp4:\n",
      "\n",
      "number of frames: 3983\n",
      "frame size: 720 x 540 \n",
      "\n",
      "(4930,)\n",
      "(4930,)\n",
      "volunteer06.mp4:\n",
      "\n",
      "number of frames: 4943\n",
      "frame size: 672 x 480 \n",
      "\n",
      "(4592,)\n",
      "(4592,)\n",
      "volunteer07.mp4:\n",
      "\n",
      "number of frames: 4593\n",
      "frame size: 500 x 480 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "videosList=[]\n",
    "\n",
    "for vidIdx in range(len(timeResolution)):\n",
    "    vidCv2 = cv2.VideoCapture(f'data/usliverseq-mp4/volunteer{str(vidIdx+1).zfill(2)}.mp4')\n",
    "    n_frames = int(vidCv2.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    sampleFrames = downsampleTimeResolution(timeResolution[vidIdx],minTimeResolution,n_frames,1)\n",
    "    print(sampleFrames.shape)\n",
    "    frameIdx = 0\n",
    "    frames = []\n",
    "    while(vidCv2.isOpened() and frameIdx<sampleFrames.shape[0]):\n",
    "        ret, frame = vidCv2.read()\n",
    "        if ret == True and sampleFrames[frameIdx]:\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "            frames.append(frame)\n",
    "        if ret == False:\n",
    "            break\n",
    "        frameIdx+=1\n",
    "\n",
    "    #number of frames in video:\n",
    "    print(f'volunteer{str(vidIdx+1).zfill(2)}.mp4:\\n')\n",
    "    print(\"number of frames:\" ,int(vidCv2.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "    #frame size:\n",
    "    print(\"frame size:\" ,int(vidCv2.get(cv2.CAP_PROP_FRAME_WIDTH)), \"x\", int(vidCv2.get(cv2.CAP_PROP_FRAME_HEIGHT)),'\\n')\n",
    "\n",
    "    \n",
    "    video = np.stack(frames, axis=0)\n",
    "    videosList.append(video)\n",
    "\n",
    "    cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9430fa962368ed4387251a9d1485ac69452138ff4fccfa03223f275ccfdee3b3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
